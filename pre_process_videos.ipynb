{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Videos\n",
        "\n",
        "This code is to process the videos into 5 minute chunks that collect meta data for each of those chunks and save them into a csv file. The metadata contains a mix of audio and visual information that gives the reader a holistic view of the events in chunks as well as the relevant contextual information surrounding them."
      ],
      "metadata": {
        "id": "UyaqRY9qZAIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "QCaPja2hF0O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai gitingest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdEt8zLtF5-i",
        "outputId": "eb51df04-3e9b-458d-f7e8-1e17c846a517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m262.0/262.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "id": "jpzrdFVLLe3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae36e39-1039-4dc2-a8c3-82cadbb9a310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting av\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-16.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Gemini Code"
      ],
      "metadata": {
        "id": "M34MM2glYdNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import sys\n",
        "import nest_asyncio\n",
        "from IPython.display import Audio, Image, Markdown, Video, display\n",
        "from gitingest import ingest\n",
        "from google.genai.types import CreateCachedContentConfig, GenerateContentConfig, Part\n",
        "import io, av\n",
        "from google.genai.types import Part\n",
        "import json\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "WVV6BwGVF8Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google import genai\n",
        "\n",
        "# fmt: off\n",
        "PROJECT_ID = \"multimodal-event-detection\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "# fmt: on\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "HiUx1N2pF-Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "W2REs_CRGFPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "9vahpP5VYpF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, json, shlex, subprocess, uuid\n",
        "from IPython.display import Video, display\n",
        "\n",
        "def _probe_duration_sec(video_path: str) -> float:\n",
        "    out = subprocess.check_output(shlex.split(\n",
        "        f'ffprobe -v error -show_entries format=duration -of json \"{video_path}\"'\n",
        "    ))\n",
        "    return float(json.loads(out)[\"format\"][\"duration\"])\n",
        "\n",
        "def slice_video_reencode(video_path: str, chunk_sec: int, out_dir: str):\n",
        "    \"\"\"\n",
        "    Slice into chunk_sec segments and re-encode to H.264 yuv420p + AAC so the browser can play.\n",
        "    Use -ss AFTER -i for accurate cutting; add +faststart for seekable MP4 in notebooks.\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    total = _probe_duration_sec(video_path)\n",
        "    n = max(1, math.ceil(total / chunk_sec))\n",
        "    results = []\n",
        "\n",
        "    for i in range(n):\n",
        "        start = i * chunk_sec\n",
        "        dur   = min(chunk_sec, max(0.001, total - start))\n",
        "        if dur <= 0: break\n",
        "\n",
        "        out_path = os.path.join(out_dir, f\"chunk_{i:02d}_{uuid.uuid4().hex}.mp4\")\n",
        "        cmd = (\n",
        "            f'ffmpeg -hide_banner -loglevel error '\n",
        "            f'-i \"{video_path}\" -ss {start:.3f} -t {dur:.3f} '      # ss AFTER -i = accurate seek\n",
        "            f'-analyzeduration 100M -probesize 100M '\n",
        "            f'-c:v libx264 -preset veryfast -crf 23 -pix_fmt yuv420p '\n",
        "            f'-c:a aac -b:a 128k '\n",
        "            f'-movflags +faststart \"{out_path}\"'\n",
        "        )\n",
        "        subprocess.check_call(shlex.split(cmd))\n",
        "        results.append((i, out_path, start, start + dur))\n",
        "\n",
        "    return results\n",
        "\n",
        "import json, re\n",
        "\n",
        "def parse_model_json(raw: str):\n",
        "    \"\"\"\n",
        "    Return a Python dict from a model's 'JSON' response.\n",
        "    Handles common annoyances: code fences, leading text, whitespace.\n",
        "    Raises JSONDecodeError if it truly isn't valid JSON.\n",
        "    \"\"\"\n",
        "    if raw is None:\n",
        "        raise json.JSONDecodeError(\"Empty response\", \"\", 0)\n",
        "\n",
        "    s = raw.strip()\n",
        "\n",
        "    # 1) Remove fenced code blocks if present (```json ... ``` or ``` ... ```)\n",
        "    fence_re = re.compile(r\"^\\s*```(?:json)?\\s*([\\s\\S]*?)\\s*```\\s*$\", re.IGNORECASE)\n",
        "    m = fence_re.match(s)\n",
        "    if m:\n",
        "        s = m.group(1).strip()\n",
        "\n",
        "    # 2) If there's still stray prose, try to extract the first top-level JSON object\n",
        "    #    (find first '{' and its matching closing '}' by counting braces)\n",
        "    if not s.lstrip().startswith(\"{\"):\n",
        "        # find first '{'\n",
        "        start = s.find(\"{\")\n",
        "        if start != -1:\n",
        "            # walk forward to find the matching closing brace\n",
        "            depth = 0\n",
        "            end = None\n",
        "            for i, ch in enumerate(s[start:], start=start):\n",
        "                if ch == \"{\":\n",
        "                    depth += 1\n",
        "                elif ch == \"}\":\n",
        "                    depth -= 1\n",
        "                    if depth == 0:\n",
        "                        end = i + 1\n",
        "                        break\n",
        "            if end:\n",
        "                s = s[start:end].strip()\n",
        "\n",
        "    # 3) Finally parse\n",
        "    return json.loads(s)\n",
        "\n",
        "import re\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "def shift_timestamps_in_json(\n",
        "    json_obj: Union[Dict, List],\n",
        "    segment_start_sec: float,\n",
        "    *,\n",
        "    numeric_keys: List[str] = (\"start_sec\", \"end_sec\", \"time_sec\"),\n",
        "    shift_any_key_ending_with_sec: bool = True,\n",
        "    # Optional guard to reduce double-shifting already-absolute values:\n",
        "    guard_small_values: bool = False,\n",
        "    max_clip_len_sec: float = 60.0\n",
        ") -> Union[Dict, List]:\n",
        "    \"\"\"\n",
        "    Shift timestamps by segment_start_sec in both:\n",
        "      - String values containing mm:ss or h:mm:ss patterns\n",
        "      - Numeric fields for keys like start_sec, end_sec, time_sec (or any *_sec if enabled)\n",
        "\n",
        "    Args:\n",
        "        json_obj: Parsed Gemini output (dict/list)\n",
        "        segment_start_sec: Segment start time (seconds) to add\n",
        "        numeric_keys: Exact keys to shift (if present and numeric)\n",
        "        shift_any_key_ending_with_sec: If True, also shift any numeric field whose key endswith(\"_sec\")\n",
        "        guard_small_values: If True, only shift numeric seconds if value <= max_clip_len_sec\n",
        "        max_clip_len_sec: Max seconds of the local segment to decide whether to shift when guarding\n",
        "\n",
        "    Returns:\n",
        "        Updated dict/list with shifted timestamps.\n",
        "    \"\"\"\n",
        "\n",
        "    # Matches h:mm:ss or mm:ss (1‚Äì2 digits for h and mm, 2 digits for ss)\n",
        "    # Examples: \"0:14\", \"1:30\", \"1:02:09\"\n",
        "    ts_pattern = re.compile(r\"\\b(?:(\\d{1,2}):)?([0-5]?\\d):([0-5]\\d)\\b\")\n",
        "\n",
        "    def shift_string_ts(text: str) -> str:\n",
        "        def repl(m: re.Match):\n",
        "            h = m.group(1)\n",
        "            mm = int(m.group(2))\n",
        "            ss = int(m.group(3))\n",
        "            total = (int(h) * 3600 if h is not None else 0) + mm * 60 + ss\n",
        "            total += segment_start_sec\n",
        "            # Render as h:mm:ss if >= 3600, else mm:ss\n",
        "            if total >= 3600:\n",
        "                hh = int(total // 3600)\n",
        "                rem = int(total % 3600)\n",
        "                new_mm = rem // 60\n",
        "                new_ss = rem % 60\n",
        "                return f\"{hh}:{new_mm:02d}:{new_ss:02d}\"\n",
        "            else:\n",
        "                new_mm = int(total // 60)\n",
        "                new_ss = int(total % 60)\n",
        "                return f\"{new_mm}:{new_ss:02d}\"\n",
        "        return ts_pattern.sub(repl, text)\n",
        "\n",
        "    def should_shift_numeric(key: str, val: Any) -> bool:\n",
        "        if not isinstance(val, (int, float)):\n",
        "            return False\n",
        "        if key in numeric_keys:\n",
        "            pass_ok = True\n",
        "        elif shift_any_key_ending_with_sec and key.endswith(\"_sec\"):\n",
        "            pass_ok = True\n",
        "        else:\n",
        "            return False\n",
        "        if guard_small_values:\n",
        "            return val <= max_clip_len_sec\n",
        "        return True\n",
        "\n",
        "    def walk(obj: Any) -> Any:\n",
        "        if isinstance(obj, dict):\n",
        "            new_d = {}\n",
        "            for k, v in obj.items():\n",
        "                if should_shift_numeric(k, v):\n",
        "                    new_d[k] = float(v) + float(segment_start_sec)\n",
        "                else:\n",
        "                    new_d[k] = walk(v)\n",
        "            return new_d\n",
        "        elif isinstance(obj, list):\n",
        "            return [walk(v) for v in obj]\n",
        "        elif isinstance(obj, str):\n",
        "            return shift_string_ts(obj)\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    return walk(json_obj)\n",
        "\n"
      ],
      "metadata": {
        "id": "mIZQSnfjKOQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing Code"
      ],
      "metadata": {
        "id": "CZJNGhkNYr9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LAW_ENF_SCHEMA = {\n",
        "  \"type\": \"OBJECT\",\n",
        "  \"properties\": {\n",
        "    # (A) ORIGINAL PROSE FIELDS (strings)\n",
        "    \"speech_and_audio_cues_description\": {\"type\": \"STRING\"},\n",
        "    \"audio_context_description\": {\"type\": \"STRING\"},\n",
        "    \"use_of_force_description\": {\"type\": \"STRING\"},\n",
        "    \"compliance_and_behavior_description\": {\"type\": \"STRING\"},\n",
        "    \"excessive_force_description\": {\"type\": \"STRING\"},\n",
        "    \"key_moments_summary\": {\"type\": \"STRING\"},\n",
        "\n",
        "    # (B) OBJECTIVE METRICS\n",
        "    # Scene metrics\n",
        "    \"scene_type\": {\"type\": \"STRING\", \"enum\": [\"indoor\",\"outdoor\",\"vehicle\",\"unknown\"]},\n",
        "    \"time_of_day\": {\"type\": \"STRING\", \"enum\": [\"day\",\"dusk\",\"night\",\"dawn\",\"unknown\"]},\n",
        "    \"lighting\": {\"type\": \"STRING\", \"enum\": [\"daylight\",\"night\",\"artificial\",\"low_light\",\"mixed\",\"unknown\"]},\n",
        "    \"weather\": {\"type\": \"STRING\", \"enum\": [\"clear\",\"rain\",\"snow\",\"windy\",\"fog\",\"unknown\"]},\n",
        "    \"camera_motion\": {\"type\": \"STRING\", \"enum\": [\"stable\",\"walking\",\"running\",\"vehicle_moving\",\"unknown\"]},\n",
        "\n",
        "    # Camera quality/visibility\n",
        "\n",
        "    \"camera_obfuscation_present\": {\"type\": \"BOOLEAN\"},\n",
        "    \"camera_obfuscation_spans\": {\n",
        "      \"type\": \"ARRAY\",\n",
        "      \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "          \"start_sec\": {\"type\": \"NUMBER\"},\n",
        "          \"end_sec\": {\"type\": \"NUMBER\"},\n",
        "          \"type\": {\"type\": \"STRING\", \"enum\": [\"occlusion\",\"low_resolution\",\"glare\",\"darkness\", \"blur\", \"other\"]}\n",
        "        },\n",
        "        \"required\": [\"start_sec\",\"end_sec\"]\n",
        "      }\n",
        "    },\n",
        "\n",
        "    # People counts / languages / ethnicities\n",
        "    \"officers_count\": {\"type\": \"INTEGER\"},\n",
        "    \"officer_ethnicities\": {\n",
        "      \"type\": \"ARRAY\",\n",
        "      \"items\": {\"type\": \"STRING\", \"enum\": [\n",
        "        \"white\",\"black\",\"hispanic\",\"asian\",\"native_american\",\"pacific_islander\",\"middle_eastern\",\"mixed\",\"unknown\"\n",
        "      ]}\n",
        "    },\n",
        "    \"civilians_count\": {\"type\": \"INTEGER\"},\n",
        "    \"civilian_ethnicities\": {\n",
        "      \"type\": \"ARRAY\",\n",
        "      \"items\": {\"type\": \"STRING\", \"enum\": [\n",
        "        \"white\",\"black\",\"hispanic\",\"asian\",\"native_american\",\"pacific_islander\",\"middle_eastern\",\"mixed\",\"unknown\"\n",
        "      ]}\n",
        "    },\n",
        "    \"languages\": {\"type\": \"ARRAY\", \"items\": {\"type\": \"STRING\"}},  # e.g., [\"en\",\"es\"]\n",
        "\n",
        "    # Use-of-force (objective)\n",
        "    \"use_of_force_present\": {\"type\": \"BOOLEAN\"},\n",
        "    \"use_of_force_types\": {\n",
        "      \"type\": \"ARRAY\",\n",
        "      \"items\": {\"type\": \"STRING\", \"enum\": [\n",
        "        \"physical_contact\",\"takedown\",\"baton\",\"taser_draw\",\"taser_deploy\",\n",
        "        \"firearm_draw\",\"firearm_discharge\",\"pepper_spray\",\n",
        "        \"restraint_handcuff\",\"restraint_prone\",\"other\"\n",
        "      ]}\n",
        "    },\n",
        "\n",
        "    # Excessive-force flag (objective)\n",
        "    \"potential_excessive_force_bool\": {\"type\": \"BOOLEAN\"}\n",
        "  },\n",
        "\n",
        "  # Make EVERY property required\n",
        "  \"required\": [\n",
        "    \"speech_and_audio_cues_description\",\n",
        "    \"audio_context_description\",\n",
        "    \"use_of_force_description\",\n",
        "    \"compliance_and_behavior_description\",\n",
        "    \"excessive_force_description\",\n",
        "    \"key_moments_summary\",\n",
        "\n",
        "    \"scene_type\",\n",
        "    \"time_of_day\",\n",
        "    \"lighting\",\n",
        "    \"weather\",\n",
        "    \"camera_motion\",\n",
        "\n",
        "    \"camera_obfuscation_present\",\n",
        "    \"camera_obfuscation_spans\",\n",
        "\n",
        "    \"officers_count\",\n",
        "    \"officer_ethnicities\",\n",
        "    \"civilians_count\",\n",
        "    \"civilian_ethnicities\",\n",
        "    \"languages\",\n",
        "\n",
        "    \"use_of_force_present\",\n",
        "    \"use_of_force_types\",\n",
        "    \"potential_excessive_force_bool\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "vmZTg5v545Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"\"\"\n",
        "You are an expert multimodal analysis system reviewing law-enforcement body-camera footage.\n",
        "You will receive a video segment. Your task is to analyze it objectively and return a\n",
        "JSON object that **strictly conforms** to the given schema.\n",
        "\n",
        "Follow these rules:\n",
        "\n",
        "1. **Structure**\n",
        "   - Output must be valid JSON.\n",
        "   - Every key in the schema must appear exactly once.\n",
        "   - Values must match their expected types (STRING, BOOLEAN, INTEGER, ARRAY, or OBJECT).\n",
        "   - For arrays, use [] if nothing is detected.\n",
        "   - For enums, choose one of the listed values or \"unknown\" if unsure.\n",
        "   - For booleans, use true/false (lowercase).\n",
        "   - For numeric values, use integers or floats as appropriate.\n",
        "\n",
        "2. **Descriptive fields (STRING)**\n",
        "   - Provide concise, factual summaries based solely on visible or audible evidence.\n",
        "   - Do not infer emotion, intent, or guilt.\n",
        "   - Include timestamps and all relevant details\n",
        "   - Fields: `speech_and_audio_cues_description`, `audio_context_description`,\n",
        "     `use_of_force_description`, `compliance_and_behavior_description`,\n",
        "     `excessive_force_description`, `key_moments_summary`.\n",
        "\n",
        "3. **Objective metrics**\n",
        "   - `scene_type`, `time_of_day`, `lighting_enum`, `weather_enum`, `camera_motion_enum`:\n",
        "     classify the environment.\n",
        "   - `camera_obfuscation_present`: true/false based on visibility.\n",
        "   - `camera_obfuscation_spans`: list timestamps in seconds when issues occur.\n",
        "   - `officers_count`, `civilians_count`: numeric counts of visible individuals.\n",
        "   - `officer_ethnicities` / `civilian_ethnicities`: arrays of observed ethnicities.\n",
        "   - `languages`: array of spoken or heard languages (e.g., [\"en\",\"es\"]).\n",
        "   - `use_of_force_present`: true if any physical contact or weapon use occurs.\n",
        "   - `use_of_force_types`: list all detected force categories.\n",
        "   - `potential_excessive_force_bool`: true only if the clip contains potential overuse (e.g., force after compliance).\n",
        "\n",
        "4. **If information is NOT observable**\n",
        "   - For enums: \"unknown\"\n",
        "   - For booleans: false\n",
        "   - For integers: 0\n",
        "   - For arrays: []\n",
        "   - For strings: \"unknown\"\n",
        "\n",
        "Return ONLY the JSON. Do not include explanations or comments outside the JSON.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Jbfhe0bBSIvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_gemini(video_path: str) -> dict:\n",
        "    with open(video_path, \"rb\") as f:\n",
        "        video_bytes = f.read()\n",
        "\n",
        "    contents = [\n",
        "        PROMPT,\n",
        "        Part.from_bytes(data=video_bytes, mime_type=\"video/mp4\"),\n",
        "    ]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=contents,\n",
        "        config={\n",
        "            # Forces JSON output that conforms to the schema\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "            \"response_schema\": LAW_ENF_SCHEMA\n",
        "        }\n",
        "    )\n",
        "\n",
        "    raw = response.text.strip()\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # Extremely defensive: fallback to a dict of unknowns if something goes wrong\n",
        "        print(\"ERROR\")\n",
        "\n",
        "    # Ensure all required keys exist (in case the model omitted any)\n",
        "    for k in LAW_ENF_SCHEMA[\"required\"]:\n",
        "        parsed.setdefault(k, None)\n",
        "\n",
        "    return parsed"
      ],
      "metadata": {
        "id": "POhoo-VcRPMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "cbGIfhnwYRRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# --- Config ---\n",
        "VIDEO_DIR = \"/content/\"    # folder containing your videos\n",
        "CHUNK_MIN = 5\n",
        "CHUNK_SEC = CHUNK_MIN * 60\n",
        "OUT_DIR   = \"/content/chunks\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- Helper: build summary string ---\n",
        "def build_summary(data):\n",
        "    parts = []\n",
        "    for k, v in data.items():\n",
        "        if k not in (\"start_sec\", \"end_sec\", \"segment_idx\", \"summary\"):\n",
        "            parts.append(f\"{k}: {v}\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "# --- Process all videos in directory ---\n",
        "for file in os.listdir(VIDEO_DIR):\n",
        "    if not file.lower().endswith((\".mp4\", \".mov\", \".mkv\", \".avi\")):\n",
        "        continue\n",
        "\n",
        "    video_path = os.path.join(VIDEO_DIR, file)\n",
        "    base_name = os.path.splitext(os.path.basename(file))[0]\n",
        "    csv_path = os.path.join(OUT_DIR, f\"{base_name}.csv\")\n",
        "\n",
        "    # ‚úÖ Skip if CSV already exists\n",
        "    if os.path.exists(csv_path):\n",
        "        print(f\"‚öôÔ∏è  Skipping {base_name} ‚Äî already processed ({csv_path})\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüé• Processing {base_name} ...\")\n",
        "\n",
        "    # Slice the video into 5-min (configurable) chunks\n",
        "    slices = slice_video_reencode(video_path, CHUNK_SEC, OUT_DIR)\n",
        "    print(f\"Sliced into {len(slices)} chunk(s) of ~{CHUNK_MIN} min each.\\n\")\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for idx, path, start, end in slices:\n",
        "        print(f\"Chunk {idx} [{start:.1f}s ‚Üí {end:.1f}s] ‚Üí {path}\")\n",
        "\n",
        "        try:\n",
        "            # 1. Run Gemini on this segment\n",
        "            data = process_gemini(path)\n",
        "\n",
        "            # 2. Parse JSON output\n",
        "            # data = parse_model_json(output)\n",
        "\n",
        "            # 3. Adjust timestamps based on segment start\n",
        "            data = shift_timestamps_in_json(data, start)\n",
        "\n",
        "            # 4. Add metadata\n",
        "            data[\"segment_idx\"] = idx\n",
        "            data[\"start_sec\"] = start\n",
        "            data[\"end_sec\"] = end\n",
        "\n",
        "            # 5. Create human-readable summary\n",
        "            data[\"summary\"] = build_summary(data)\n",
        "\n",
        "            rows.append(data)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing chunk {idx}: {e}\")\n",
        "\n",
        "    # Combine all chunks into a DataFrame\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Save to CSV named after the video\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"‚úÖ Saved analysis ‚Üí {csv_path}\\n\")\n",
        "\n",
        "print(\"\\n‚úÖ All videos processed.\")\n"
      ],
      "metadata": {
        "id": "zqjlz1YjT5hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f88066-5853-456b-a9ef-78e393c13dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-12-05 21:04:34.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlogging\u001b[0m:\u001b[36mcallHandlers\u001b[0m:\u001b[36m1762\u001b[0m | NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üé• Processing 17-183-0765 BWC_Redacted-2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-12-05 21:04:47.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlogging\u001b[0m:\u001b[36mcallHandlers\u001b[0m:\u001b[36m1762\u001b[0m | AFC is enabled with max remote calls: 10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced into 1 chunk(s) of ~5 min each.\n",
            "\n",
            "Chunk 0 [0.0s ‚Üí 12.7s] ‚Üí /content/chunks/chunk_00_dfce69b0bd41429caea44df1d53b5f72.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-12-05 21:05:02.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlogging\u001b[0m:\u001b[36mcallHandlers\u001b[0m:\u001b[36m1762\u001b[0m | HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/multimodal-event-detection/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved analysis ‚Üí /content/chunks/17-183-0765 BWC_Redacted-2.csv\n",
            "\n",
            "\n",
            "‚úÖ All videos processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the csv files"
      ],
      "metadata": {
        "id": "cDwHe56xY5kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "OUT_DIR = \"/content/chunks\"\n",
        "ZIP_PATH = \"/content/chunks_output.zip\"\n",
        "\n",
        "# 1Ô∏è‚É£ Remove all .mp4 files\n",
        "!find {OUT_DIR} -type f -name \"*.mp4\" -delete\n",
        "print(\"üóëÔ∏è  All .mp4 files removed from\", OUT_DIR)\n",
        "\n",
        "# 2Ô∏è‚É£ Zip the remaining files\n",
        "shutil.make_archive(ZIP_PATH.replace(\".zip\", \"\"), 'zip', OUT_DIR)\n",
        "print(f\"üì¶ Created ZIP: {ZIP_PATH}\")\n",
        "\n",
        "# 3Ô∏è‚É£ Trigger download\n",
        "files.download(ZIP_PATH)\n"
      ],
      "metadata": {
        "id": "I_Tw8pMdxBi2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "e2d25be7-20bf-4e63-d9a1-685c8e97d117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üóëÔ∏è  All .mp4 files removed from /content/chunks\n",
            "üì¶ Created ZIP: /content/chunks_output.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a0e9104-72dc-4e5e-8fcf-66c72cd48d69\", \"chunks_output.zip\", 28522)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}